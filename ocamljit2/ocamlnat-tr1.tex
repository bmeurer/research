\documentclass[10pt,a4paper,draft,twocolumn]{article}

\usepackage{amssymb}
\usepackage[english]{babel}
\usepackage{color}
\usepackage{enumerate}
\usepackage[colorlinks=false,%
            pdfkeywords={OCaml, Just In Time compilation, machine code generation},%
            pdftitle={Towards a native toplevel for OCaml},%
            pdfauthor={Marcell Fischbach, Benedikt Meurer},%
            pdfsubject={},%
            pdfdisplaydoctitle=true]{hyperref}
\usepackage{tikz}
\usepackage{varwidth}
\usepackage{xspace}

\newcommand{\etc}{etc.\@\xspace}
\newcommand{\ie}{i.e.\@\xspace}

\usetikzlibrary{arrows}
\usetikzlibrary{trees}
\usetikzlibrary{arrows,backgrounds,decorations.pathmorphing,fit,matrix,positioning}
\tikzset{
  phase/.style={
      rectangle,
      inner sep=1mm,
      rounded corners=1mm,
      minimum size=6mm,
      very thick,
      draw=blue!50!black!50,
      top color=white,
      bottom color=blue!50!black!20
  }
}

\begin{document}

\title{%
  Towards a native toplevel for OCaml
}
\author{%
  Marcell Fischbach\thanks{
    Universit\"at Siegen,
    D-57068 Siegen,
    Germany,
    \url{marcellfischbach@googlemail.com}
  }
  \and
  Benedikt Meurer\thanks{
    Compilerbau und Softwareanalyse,
    Naturwissenschaftl.-Technische Fakult\"at,
    Universit\"at Siegen,
    D-57068 Siegen,
    Germany,
    \url{meurer@informatik.uni-siegen.de}
  }
}
\date{}

\maketitle

\begin{abstract}
  TODO
\end{abstract}


%% Introduction
\section{Introduction}

The OCaml \cite{Leroy11,Remy02} system is the main implementation of the Caml
language \cite{Caml11}, featuring a powerful module system
combined with a full-fledged object-oriented layer. It ships with an optimizing native
code compiler \texttt{ocamlopt}, for high performance; a byte code compiler \texttt{ocamlc}
and interpreter \texttt{ocamlrun}, for increased portability; and an interactive top-level
\texttt{ocaml} based on the byte code compiler and runtime, for interactive use of OCaml
through a read-eval-print loop.

\texttt{ocamlc} and \texttt{ocaml} translate the source code into a sequence of byte code
instructions for the OCaml virtual machine \texttt{ocamlrun}, which is based on the ZINC
machine \cite{Leroy90} originally developed for Caml Light \cite{Leroy02}. The optimizing
native code compiler \texttt{ocamlopt} produces fast machine code for the supported targets
(at the time of this writing, these are Alpha, ARM, Itanum, Motorola 68k, MIPS, PA-RISC, PowerPC,
Sparc, and x86/x86-64), but is currently only applicable to \emph{static program compilation}.
For example, it cannot yet be used with multi-stage programming in MetaOCaml \cite{Taha03,Taha06},
the Coq proof assistant \cite{Bertot04,Coq10}, or the interactive toplevel \texttt{ocaml}.

This paper presents our work\footnote{The initial work in this area was done as part of the first
author's diploma thesis.} on a new native OCaml toplevel, called \texttt{ocamlnat}, which is
based on the native runtime, the compilation engine of the optimizing native code compiler and
an earlier prototype implementation of a native toplevel by Alain Frisch. The full source code
is available from the \texttt{ocamljit-nat} branch of the \texttt{ocaml-experimental} Git
repository hosted on GitHub at \url{https://github.com/bmeurer/ocaml-experimental/}.

The paper is organized as follows: Section~\ref{section:Motivation} motivates the need for a
usable native OCaml toplevel. Section~\ref{section:Overview_of_the_OCaml_compilers} presents
an overview of the OCaml compilers and Section~\ref{section:The_native_toplevel} describes the
previous \texttt{ocamlnat} prototype which inspired our work, while
Section~\ref{section:Just_in_time_code_generation} presents our work on \texttt{ocamlnat}.
Performance measures are given in Section~\ref{section:Performance}.
Section~\ref{section:Conclusion_and_further_work} concludes with possible directions for
further work.


%% Motivation
\section{Motivation} \label{section:Motivation}

\begin{enumerate}
\item Speed
\item Mirage \cite{Mirage11,Madhavapeddy10,Madhavapeddy10hotcloud}
\item ocamlscript \cite{ocamlscript11}
\item Memory Overhead
\end{enumerate}

\textbf{TODO}


%% Overview of the OCaml compilers
\section{Overview of the OCaml compilers} \label{section:Overview_of_the_OCaml_compilers}

This section gives a brief overview of the OCaml compilers, covering both the byte code compiler
\texttt{ocamlc} and the optimizing native code compiler \texttt{ocamlopt}.
Feel free to skip to section~\ref{section:The_native_toplevel} if you are already familiar with the details.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=8mm,text height=1.5ex,text depth=.25ex]
    \matrix[row sep={1.3cm,between origins}]
    {
      & \node (start) {}; \\
      & \node[phase] (parsing) {Parsing}; \\
      & \node[phase] (typing) {Typing}; \\
      & \node[phase] (transl) {Translate}; \\
      & \node[phase] (simplif) {Simplify}; \\
      \node[phase] (bytegen) {Bytegen}; && \node[phase] (asmgen) {Asmgen}; \\
      \node (bytecode) {}; && \node (nativecode) {}; \\
    };
    \draw[->] (start) -- node[right] {\it source program} (parsing);
    \draw[->] (parsing) -- node[right] {\tt Parsetree} (typing);
    \draw[->] (typing) -- node[right] {\tt Typedtree} (transl);
    \draw[->] (transl) -- node[right] {\tt Lambda} (simplif);
    \draw[->] (simplif) -- node[left] {} (bytegen);
    \draw[->] (simplif) -- node[right] {} (asmgen);
    \draw[->] (bytegen) -- node[left] {\it byte code} (bytecode);
    \draw[->] (asmgen) -- node[right] {\it native code} (nativecode);
  \end{tikzpicture}
  \caption{Overview of the OCaml compilers}
  \label{fig:Overview_of_the_OCaml_compilers}
\end{figure}

Figure~\ref{fig:Overview_of_the_OCaml_compilers} gives an overview of the compiler phases
and representations in the OCaml byte and native code compilers. Compilation always starts
by parsing an OCaml source program (either from a source file or a source region in
interactive mode) into an abstract syntax tree (AST, see file \texttt{parsing/parsetree.mli}
of the OCaml source code). Compilation then proceeds by computing the type annotations to
produce a typed syntax tree (see file \texttt{typing/typedtree.mli}).

From this typed syntax tree, the compiler generates a so called \emph{lambda representation} (see file
\texttt{bytecomp/lambda.mli}) inspired by the untyped call-by-value $\lambda$-calculus
\cite{Appel98ml,Jones87,Michaelson89}. This lambda representation is then optimized by
transforming lambda trees into \emph{better} or smaller lambda trees (see file
\texttt{bytecomp/simplif.ml}), yielding a final platform independent, internal
representation of the source program as result of the compiler frontend phases.

The simplified lambda representation is then used as input for the respective compiler
backend, which is
\begin{itemize}
\item the \texttt{Bytegen} module in case of the byte code compiler
  (see file \texttt{bytecomp/bytegen.ml}), or
\item the \texttt{Asmgen} module in case of the optimizing native code compiler
  (see file \texttt{asmcomp/asmgen.ml}).
\end{itemize}

The byte code backend, which is used by the byte code compiler \texttt{ocamlc} as well as
the byte code toplevel \texttt{ocaml}, basically turns the simplified lambda representation
into an equivalent byte code program (see file \texttt{bytecomp/instruct.mli}), suitable for
(a) direct execution by the byte code interpreter \texttt{ocamlrun} or (b) just-in-time
compilation using either OCAMLJIT \cite{Starynkevitch04} or OCamlJIT2
\cite{Meurer10jit,Meurer10ocamljit,Meurer11ocamljit2}.
This is done by the \texttt{Emitcode} module (see file \texttt{bytecomp/emitcode.ml}).
Additional details about the byte code compiler and runtime can be found in \cite{Leroy90},
\cite{Meurer10ocamljit} and \cite{Starynkevitch04}.

The native code backend, which is used by the optimizing native code compiler \texttt{ocamlopt}
as well as the native toplevel \texttt{ocamlnat}, is shown in Figure~\ref{fig:Native_code_generation}.
It takes the simplified lambda representation as input and starts by transforming it into a variant
of the lambda representation (see file \texttt{asmcomp/clambda.mli}) with explicit closures and
explicit direct/indirect function calls (see file \texttt{asmcomp/closure.ml}). This is then further
processed and transformed into an equivalent representation in an internal dialect of C\mbox{-}\mbox{-}
\cite{JonesR98,JonesRR99} (see files \texttt{asmcomp/cmm.mli} and \texttt{asmcomp/cmmgen.ml}).

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=8mm,text height=1.5ex,text depth=.25ex]
    \matrix[row sep={1.3cm,between origins}]
    {
      \node (start) {}; \\
      \node[phase] (closure) {Closure conversion}; \\
      \node[phase] (cmmgen) {C\mbox{-}\mbox{-} generation}; \\
      \node[phase] (selection) {Instruction selection}; \\
      \node[phase] (comballoc) {Alloc combining}; \\
      \node[phase] (regalloc) {Register allocation}; \\
      \node[phase] (linearize) {Linearization}; \\
      \node[phase] (scheduling) {Instruction scheduling}; \\
      \node (end) {}; \\
    };
    \draw[->] (start) -- node[right] {\tt Lambda} (closure);
    \draw[->] (closure) -- node[right] {\tt Clambda} (cmmgen);
    \draw[->] (cmmgen) -- node[right] {\tt Cmm} (selection);
    \draw[->] (selection) -- node[right] {\tt Mach} (comballoc);
    \draw[->] (comballoc) -- node[right] {\tt Mach} (regalloc);
    \draw[->] (regalloc) -- node[right] {\tt Mach} (linearize);
    \draw[->] (linearize) -- node[right] {\tt Linearize} (scheduling);
    \draw[->] (scheduling) -- node[right] {\it native code} (end);
  \end{tikzpicture}
  \caption{Native code generation (\texttt{Asmgen} module)}
  \label{fig:Native_code_generation}
\end{figure}

Afterwards the Instruction selection phase (see file \texttt{asmcomp/selection.ml}) picks appropriate
instructions for the target machine, transforming the C\mbox{-}\mbox{-} code into non-linear machine
code (see file \texttt{asmcomp/mach.mli}). The next step attempts to combine multiple heap allocations
within a basic block into a single heap allocation (see file \texttt{asmcomp/comballoc.ml}), prior to
allocating and assigning physical registers to the virtual registers used in the machine code (see
function \texttt{regalloc} in file \texttt{asmcomp/asmgen.ml}).
The final phases linearize the machine code (see file \texttt{asmcomp/linearize.ml}) and perform
instruction scheduling for better performance (see file \texttt{asmcomp/scheduling.ml}), yielding the
final representation of the (linearized) machine code.

The optimizing native code compiler \texttt{ocamlopt} writes the linearized machine code output of
the \texttt{Asmgen} module to an assembly file in the appropriate format for the target platform (see
file \texttt{asmcomp/emit.ml}), \ie using AT\&T assembly syntax on Linux and Intel assembly syntax
on Windows, and invokes the assembler from the system compiler toolchain, \ie GNU \texttt{as} on Linux,
to generate an object file. This object file can then be linked with other OCaml modules and C code into
an executable binary or a dynamic library file.


%% The native toplevel
\section{The native toplevel} \label{section:The_native_toplevel}

In 2007 Alain Frisch added support for the \texttt{Dynlink} library to the native code compiler and
runtime, which was first made available as part of OCaml 3.11. This change made it possible to use
the OCaml native code runtime with dynamically loaded plugins, a feature that was previously only
available with the byte code runtime. Besides various other benefits, this also made it possible
to reuse the existing functionality of the optimizing native code compiler within the scope of a
native toplevel.

The initial proof-of-concept prototype of a native toplevel, developed by Alain Frisch and named
\texttt{ocamlnat}, was since silently shipped with every OCaml release\footnote{It must be build
explicitly using \texttt{make ocamlnat} after \texttt{make world} and \texttt{make opt}, and it
is only available for targets that support the native \texttt{Dynlink} library.}.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=8mm,text height=1.5ex,text depth=.25ex]
    \matrix[row sep={1.3cm,between origins}]
    {
      \node (start) {}; \\
      \node[phase] (compiler) {Native code compiler}; \\
      \node[phase] (emit) {Native code emitter}; \\
      \node[phase] (as) {Toolchain Assembler (\texttt{as})}; \\
      \node[phase] (ld) {Toolchain Linker (\texttt{ld})}; \\
      \node[phase] (rtld) {Runtime Linker}; \\
      \node (end) {}; \\
    };
    \draw[->] (start) -- node[right] {\it OCaml phrase} (compiler);
    \draw[->] (compiler) -- node[right] {\it native code} (emit);
    \draw[->] (emit) -- node[right] {\it assembly file} (as);
    \draw[->] (as) -- node[right] {\it object file} (ld);
    \draw[->] (ld) -- node[right] {\it dynamic library file} (rtld);
    \draw[->] (rtld) -- node[right] {\it executable code} (end);
  \end{tikzpicture}
  \caption{\texttt{ocamlnat} prototype}
  \label{fig:ocamlnat_prototype}
\end{figure}

Figure~\ref{fig:ocamlnat_prototype} gives an overview of the internals of this \texttt{ocamlnat} prototype.
It works by starting up the OCaml native runtime and then prompts the user for OCaml phrases to evaluate
(just like the byte code toplevel \texttt{ocaml} does). Whenever the user enters a phrase, it is compiled
to native code using the modules of the optimizing native code compiler (utilizing the frontend phases as
shown in Figure~\ref{fig:Overview_of_the_OCaml_compilers} and the native backend phases as shown in
Figure~\ref{fig:Native_code_generation}).

This \emph{native code} is written to a temporary \emph{assembly file} by the Native code emitter, which
is also part of \texttt{ocamlopt}. The \emph{assembly file} is then passed to the Toolchain Assembler, \ie GNU
\texttt{as} on Linux, to produce a temporary \emph{object file}. This \emph{object file} is afterwards turned
into a \emph{dynamic library file} by the Toolchain Linker, \ie GNU \texttt{ld} on Linux, and loaded into the
native toplevel process using the Runtime Linker, finally yielding a memory area with the \emph{executable code}
which is then executed.

While this approach has the immediate benefit of requiring only a few hundred lines of glue code to turn
the existing modules of the optimizing native code compiler and the native \texttt{Dynlink} library into
a native toplevel, there are also various obvious drawbacks to this approach (preventing wide-spread
adoption of \texttt{ocamlnat}):
\begin{enumerate}
\item Dependency on the system toolchain (as, ld).
  Problematic for Mirage \cite{Mirage11,Madhavapeddy10,Madhavapeddy10hotcloud}.
  \textbf{TODO}
\item Latency of the external tools and the necessary I/O. \textbf{TODO}
\item Left-over temporary files on (DLLs on Windows). \textbf{TODO}
\item Unclear maintenance status. \textbf{TODO}
\end{enumerate}


%% Just-in-Time code generation
\section{Just-in-Time code generation} \label{section:Just_in_time_code_generation}

We aim to improve \texttt{ocamlnat} in a way that avoids the drawbacks of the earlier prototype
and turns the native toplevel into a viable alternative to the byte code toplevel. As noted above,
the major drawback of Alain's prototype is the dependency on the system toolchain, that is, the
external assembler and linker programs.

Therefore we had to replace the last four phases of the \texttt{ocamlnat} prototype as shown in
Figure~\ref{fig:ocamlnat_prototype} with something that does not depend on any external programs
but does the executable code generation just-in-time in the native toplevel process.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[node distance=8mm,text height=1.5ex,text depth=.25ex]
    \matrix[row sep={1.3cm,between origins}]
    {
      \node (start) {}; \\
      \node[phase] (compiler) {Native code compiler}; \\
      \node[phase] (jit) {Just-in-Time Emitter}; \\
      \node[phase] (jitld) {Just-in-Time Linker}; \\
      \node (end) {}; \\
    };
    \draw[->] (start) -- node[right] {\it OCaml phrase} (compiler);
    \draw[->] (compiler) -- node[right] {\it native code} (jit);
    \draw[->] (jit) -- node[right] {\it object code} (jitld);
    \draw[->] (jitld) -- node[right] {\it executable code} (end);
  \end{tikzpicture}
  \caption{\texttt{ocamlnat} overview}
  \label{fig:ocamlnat_overview}
\end{figure}

Figure~\ref{fig:ocamlnat_overview} shows our current implementation. As you can see we replaced
the Native code emitter and Toolchain Assembler phases from the \texttt{ocamlnat} prototype with
a Just-in-Time Emitter phase, and the Toolchain Linker and Runtime Linker phases with a Just-in-Time
Linker phase. The earlier phases, that are shared with the optimizing native code compiler
\texttt{ocamlopt} as described in Section~\ref{section:Overview_of_the_OCaml_compilers} and
\ref{section:The_native_toplevel}, remain unchanged.

The Just-in-Time Emitter phase is responsible for transforming the linearized native code that is
generated by the Native code compiler (as shown in Figure~\ref{fig:Native_code_generation}) into
\emph{object code} for the target platform. This \emph{object code} is very similar to the \emph{object
file} generated by the Toolchain Assembler; it contains a \texttt{text} section with the executable
code, a \texttt{data} section with the associated data items (\ie the floating-point constants, closures
and string literals used within the code, the frametable for the garbage collector, \ldots), a list
of relocations, and a list of global symbols.

The Just-in-Time Linker phase allocates executable memory for the \texttt{text} section and writable
memory for the \texttt{data} section, copies the section contents to their final memory locations,
takes care of the relocations, and registers the global symbols. This is roughly what the Toolchain
Linker and Runtime Linker do in the \texttt{ocamlnat} prototype.

The code for the two phases is found in the \texttt{toplevel/jitaux.ml} file, which provides the common
functionality for Just-in-Time code generation, as well as \texttt{toplevel/amd64/jit.ml} for the x86-64
platform and \texttt{toplevel/i386/jit.ml} for the x86 platform, plus a few lines of additional C code in
\texttt{asmrun/natdynlink.c} and \texttt{asmrun/natjit.c}. At the time of this writing the changes for our
new native toplevel with support for x86 and x86-64 account for approximately 2300 lines of C and OCaml
code as shown in Figure~\ref{fig:Additional_lines_of_code_for_ocamlnat}.

\begin{figure}[htb]
  \centering
  \begin{tabular}{r|rr}
    & OCaml & C \\
    \hline
    Generic & $277$ & $185$ \\
    amd64 & $863$ & $\diagup$\, \\
    i386 & $991$ & $\diagup$\, \\
    \hline
    & $2131$ & $185$ \\
  \end{tabular}
  \caption{Additional lines of code for \texttt{ocamlnat}}
  \label{fig:Additional_lines_of_code_for_ocamlnat}
\end{figure}

We tried to keep the code as easy to maintain as possible. To achieve this goal we
\begin{enumerate}[(a)]
\item reused as much of the existing functionality as possible with respect to both the native code compiler and
  its runtime,
\item kept the amount of additional runtime support as low as possible (basically just an additional layer in
  the global symbol management and a new entry point for the Just-in-Time code execution), and
\item made the Just-in-Time Emitter (the \texttt{jit.ml} files in the \texttt{toplevel} subdirectories) look as
  similar as possible to the Native Code Emitter (the \texttt{emit.mlp} files in the \texttt{asmcomp}
  subdirectories).
\end{enumerate}
The last point is especially important as every change to the Native Code Emitters
(\ie \texttt{asmcomp/amd64/emit.mlp}) must be reflected by an equivalent change to the appropriate
Just-in-Time Emitter (\ie \texttt{toplevel/amd64/jit.ml}). Fortunately the Native Code Emitters usually
do not change very often during the OCaml development process.


%% Performance
\section{Performance} \label{section:Performance}

TODO


%% Conclusion and further work
\section{Conclusion and further work} \label{section:Conclusion_and_further_work}

\begin{enumerate}
\item Additional targets.
\item Integration into Mirage \cite{Mirage11,Madhavapeddy10,Madhavapeddy10hotcloud}.
\item Reuse for custom binary emitters to avoid the toolchain dependency of \texttt{ocamlopt}.
\item Integration with Linear Scan.
\end{enumerate}

TODO


%% References
\bibliographystyle{abbrv}
\bibliography{citations}

\end{document}
